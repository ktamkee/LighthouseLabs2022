{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0678f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "sc =SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8607b7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a collection of data called RDD\n",
    "nums = sc.parallelize([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5d88da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31277c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "4 \n",
      "9 \n",
      "16 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Apply transformation to the data\n",
    "squared = nums.map(lambda x: x*x).collect()\n",
    "for num in squared:\n",
    "    print('%i ' % (num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "665a84b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a974bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of tuple with the information\n",
    "list_p = [('John',19),('Smith',29),('Adam',35),('Henry',50)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf414064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the RDD\n",
    "rdd = sc.parallelize(list_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e55b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Tuples\n",
    "ppl = rdd.map(lambda x: Row(name=x[0], age=int(x[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8145e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame context\n",
    "DF_ppl = sqlContext.createDataFrame(ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5616437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Access the type of each feature\n",
    "DF_ppl.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9ea843",
   "metadata": {},
   "source": [
    "# Machine Learning Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0240b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/sadhana1002/PredictingSalaryClass-Classification/master/adult.csv\"\n",
    "df = sqlContext.createDataFrame(pd.read_csv(url, \n",
    "                                      names=['Age','workclass',\n",
    "                                             'fnlwgt','education',\n",
    "                                             'education_num',\n",
    "                                             'marital',\n",
    "                                             'occupation',\n",
    "                                             'relationship','race',\n",
    "                                             'sex','capital_gain',\n",
    "                                             'capital_loss',\n",
    "                                             'hours_week',\n",
    "                                             'native_country','label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bde2218d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: long (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: long (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- education_num: long (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital_gain: long (nullable = true)\n",
      " |-- capital_loss: long (nullable = true)\n",
      " |-- hours_week: long (nullable = true)\n",
      " |-- native_country: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at the data type\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94f9312c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+------+----------+-------------+-------------------+------------------+--------------+------+-------+------------+------------+----------+--------------+------+\n",
      "|Age|workclass        |fnlwgt|education |education_num|marital            |occupation        |relationship  |race  |sex    |capital_gain|capital_loss|hours_week|native_country|label |\n",
      "+---+-----------------+------+----------+-------------+-------------------+------------------+--------------+------+-------+------------+------------+----------+--------------+------+\n",
      "|39 | State-gov       |77516 | Bachelors|13           | Never-married     | Adm-clerical     | Not-in-family| White| Male  |2174        |0           |40        | United-States| <=50K|\n",
      "|50 | Self-emp-not-inc|83311 | Bachelors|13           | Married-civ-spouse| Exec-managerial  | Husband      | White| Male  |0           |0           |13        | United-States| <=50K|\n",
      "|38 | Private         |215646| HS-grad  |9            | Divorced          | Handlers-cleaners| Not-in-family| White| Male  |0           |0           |40        | United-States| <=50K|\n",
      "|53 | Private         |234721| 11th     |7            | Married-civ-spouse| Handlers-cleaners| Husband      | Black| Male  |0           |0           |40        | United-States| <=50K|\n",
      "|28 | Private         |338409| Bachelors|13           | Married-civ-spouse| Prof-specialty   | Wife         | Black| Female|0           |0           |40        | Cuba         | <=50K|\n",
      "+---+-----------------+------+----------+-------------+-------------------+------------------+--------------+------+-------+------------+------------+----------+--------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See the data\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c60dc449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: float (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: float (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- education_num: float (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital_gain: float (nullable = true)\n",
      " |-- capital_loss: float (nullable = true)\n",
      " |-- hours_week: float (nullable = true)\n",
      " |-- native_country: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert the continuous variables\n",
    "\n",
    "# Import all from `sql.types`\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Write a custom function to convert the data type of DataFrame columns\n",
    "def convertColumn(df, names, newType):\n",
    "    for name in names: \n",
    "        df = df.withColumn(name, df[name].cast(newType))\n",
    "    return df \n",
    "# List of continuous features\n",
    "CONTI_FEATURES  = ['age', 'fnlwgt','capital_gain', 'education_num', 'capital_loss', 'hours_week']\n",
    "# Convert the type\n",
    "df = convertColumn(df, CONTI_FEATURES, FloatType())\n",
    "# Check the dataset\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82c6ac39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "| age|  fnlwgt|\n",
      "+----+--------+\n",
      "|39.0| 77516.0|\n",
      "|50.0| 83311.0|\n",
      "|38.0|215646.0|\n",
      "|53.0|234721.0|\n",
      "|28.0|338409.0|\n",
      "+----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select columns\n",
    "df.select('age','fnlwgt').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61465e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|    education|count|\n",
      "+-------------+-----+\n",
      "|    Preschool|   51|\n",
      "|      1st-4th|  168|\n",
      "|      5th-6th|  333|\n",
      "|    Doctorate|  413|\n",
      "|         12th|  433|\n",
      "|          9th|  514|\n",
      "|  Prof-school|  576|\n",
      "|      7th-8th|  646|\n",
      "|         10th|  933|\n",
      "|   Assoc-acdm| 1067|\n",
      "|         11th| 1175|\n",
      "|    Assoc-voc| 1382|\n",
      "|      Masters| 1723|\n",
      "|    Bachelors| 5355|\n",
      "| Some-college| 7291|\n",
      "|      HS-grad|10501|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count by group\n",
    "df.groupBy(\"education\").count().sort(\"count\",ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef3c7333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------+------------------+-------------+------------------+---------+-----------------+------------+-------------------+-------+------------------+------------------+------------------+--------------+------+\n",
      "|summary|               age|   workclass|            fnlwgt|    education|     education_num|  marital|       occupation|relationship|               race|    sex|      capital_gain|      capital_loss|        hours_week|native_country| label|\n",
      "+-------+------------------+------------+------------------+-------------+------------------+---------+-----------------+------------+-------------------+-------+------------------+------------------+------------------+--------------+------+\n",
      "|  count|             32561|       32561|             32561|        32561|             32561|    32561|            32561|       32561|              32561|  32561|             32561|             32561|             32561|         32561| 32561|\n",
      "|   mean| 38.58164675532078|        null|189778.36651208502|         null|  10.0806793403151|     null|             null|        null|               null|   null|1077.6488437087312|   87.303829734959|40.437455852092995|          null|  null|\n",
      "| stddev|13.640432553581343|        null| 105549.9776970223|         null|2.5727203320673877|     null|             null|        null|               null|   null| 7385.292084840335|402.96021864899984|12.347428681731847|          null|  null|\n",
      "|    min|              17.0|           ?|           12285.0|         10th|               1.0| Divorced|                ?|     Husband| Amer-Indian-Eskimo| Female|               0.0|               0.0|               1.0|             ?| <=50K|\n",
      "|    max|              90.0| Without-pay|         1484705.0| Some-college|              16.0|  Widowed| Transport-moving|        Wife|              White|   Male|           99999.0|            4356.0|              99.0|    Yugoslavia|  >50K|\n",
      "+-------+------------------+------------+------------------+-------------+------------------+---------+-----------------+------------+-------------------+-------+------------------+------------------+------------------+--------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Describe the data\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a40ca8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      capital_gain|\n",
      "+-------+------------------+\n",
      "|  count|             32561|\n",
      "|   mean|1077.6488437087312|\n",
      "| stddev| 7385.292084840335|\n",
      "|    min|               0.0|\n",
      "|    max|           99999.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe('capital_gain').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ea1a78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-----+\n",
      "|age_label| <=50K| >50K|\n",
      "+---------+------+-----+\n",
      "|     17.0|   395|    0|\n",
      "|     18.0|   550|    0|\n",
      "|     19.0|   710|    2|\n",
      "|     20.0|   753|    0|\n",
      "|     21.0|   717|    3|\n",
      "|     22.0|   752|   13|\n",
      "|     23.0|   865|   12|\n",
      "|     24.0|   767|   31|\n",
      "|     25.0|   788|   53|\n",
      "|     26.0|   722|   63|\n",
      "|     27.0|   754|   81|\n",
      "|     28.0|   748|  119|\n",
      "|     29.0|   679|  134|\n",
      "|     30.0|   690|  171|\n",
      "|     31.0|   705|  183|\n",
      "|     32.0|   639|  189|\n",
      "|     33.0|   684|  191|\n",
      "|     34.0|   643|  243|\n",
      "|     35.0|   659|  217|\n",
      "|     36.0|   635|  263|\n",
      "+---------+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crosstab computation\n",
    "df.crosstab('age', 'label').sort(\"age_label\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6118b0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'workclass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'marital',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'capital_gain',\n",
       " 'capital_loss',\n",
       " 'hours_week',\n",
       " 'native_country',\n",
       " 'label']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop Column\n",
    "    # drop(): drop a column\n",
    "    # dropna(): drop NA's\n",
    "    \n",
    "df.drop('education_num').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "182a2eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13443"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter data\n",
    "df.filter(df.age > 40).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "054f7273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|             marital| avg(capital_gain)|\n",
      "+--------------------+------------------+\n",
      "|             Widowed| 571.0715005035247|\n",
      "| Married-spouse-a...| 653.9832535885167|\n",
      "|   Married-AF-spouse| 432.6521739130435|\n",
      "|  Married-civ-spouse|1764.8595085470085|\n",
      "|            Divorced| 728.4148098131893|\n",
      "|       Never-married|376.58831788823363|\n",
      "|           Separated| 535.5687804878049|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Descriptive statistic by group\n",
    "df.groupby('marital').agg({'capital_gain': 'mean'}).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20166bcd",
   "metadata": {},
   "source": [
    "# Step 2 : Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29135861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: float (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: float (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- education_num: float (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital_gain: float (nullable = true)\n",
      " |-- capital_loss: float (nullable = true)\n",
      " |-- hours_week: float (nullable = true)\n",
      " |-- native_country: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- age_square: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add age square\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# 1 Select the column\n",
    "age_square = df.select(col(\"age\")**2)\n",
    "\n",
    "# 2 Apply the transformation and add it to the DataFrame\n",
    "df = df.withColumn(\"age_square\", col(\"age\")**2)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51ef9340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(age=39.0, age_square=1521.0, workclass=' State-gov', fnlwgt=77516.0, education=' Bachelors', education_num=13.0, marital=' Never-married', occupation=' Adm-clerical', relationship=' Not-in-family', race=' White', sex=' Male', capital_gain=2174.0, capital_loss=0.0, hours_week=40.0, native_country=' United-States', label=' <=50K')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMNS = ['age', 'age_square', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital',\n",
    "           'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss',\n",
    "           'hours_week', 'native_country', 'label']\n",
    "df = df.select(COLUMNS)\n",
    "df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b4194fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+\n",
      "|      native_country|count(native_country)|\n",
      "+--------------------+---------------------+\n",
      "|  Holand-Netherlands|                    1|\n",
      "|            Scotland|                   12|\n",
      "|            Honduras|                   13|\n",
      "|             Hungary|                   13|\n",
      "| Outlying-US(Guam...|                   14|\n",
      "|          Yugoslavia|                   16|\n",
      "|                Laos|                   18|\n",
      "|            Thailand|                   18|\n",
      "|            Cambodia|                   19|\n",
      "|     Trinadad&Tobago|                   19|\n",
      "|                Hong|                   20|\n",
      "|             Ireland|                   24|\n",
      "|             Ecuador|                   28|\n",
      "|              Greece|                   29|\n",
      "|              France|                   29|\n",
      "|                Peru|                   31|\n",
      "|           Nicaragua|                   34|\n",
      "|            Portugal|                   37|\n",
      "|                Iran|                   43|\n",
      "|               Haiti|                   44|\n",
      "+--------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exclude Holan-Netherlands\n",
    "df.filter(df.native_country == 'Holand-Netherlands').count()\n",
    "df.groupby('native_country').agg({'native_country': 'count'}).sort(asc(\"count(native_country)\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fedfbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remove = df.filter(df.native_country != 'Holand-Netherlands')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5479fe7d",
   "metadata": {},
   "source": [
    "# Step 2: Build a data processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50ba3a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----------------+-------+----------+-------------+-------------------+----------------+--------------+------+-----+------------+------------+----------+--------------+------+-----------------+-------------+\n",
      "| age|age_square|        workclass| fnlwgt| education|education_num|            marital|      occupation|  relationship|  race|  sex|capital_gain|capital_loss|hours_week|native_country| label|workclass_encoded|workclass_vec|\n",
      "+----+----------+-----------------+-------+----------+-------------+-------------------+----------------+--------------+------+-----+------------+------------+----------+--------------+------+-----------------+-------------+\n",
      "|39.0|    1521.0|        State-gov|77516.0| Bachelors|         13.0|      Never-married|    Adm-clerical| Not-in-family| White| Male|      2174.0|         0.0|      40.0| United-States| <=50K|              4.0|(9,[4],[1.0])|\n",
      "|50.0|    2500.0| Self-emp-not-inc|83311.0| Bachelors|         13.0| Married-civ-spouse| Exec-managerial|       Husband| White| Male|         0.0|         0.0|      13.0| United-States| <=50K|              1.0|(9,[1],[1.0])|\n",
      "+----+----------+-----------------+-------+----------+-------------+-------------------+----------------+--------------+------+-----+------------+------------+----------+--------------+------+-----------------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Example encoder\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol=\"workclass\", outputCol=\"workclass_encoded\")\n",
    "model = stringIndexer.fit(df)\n",
    "indexed = model.transform(df)\n",
    "encoder = OneHotEncoder(dropLast=False, inputCol=\"workclass_encoded\", outputCol=\"workclass_vec\").fit(indexed)\n",
    "encoded = encoder.transform(indexed)\n",
    "encoded.show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "207ad9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "CATE_FEATURES = ['workclass', 'education', 'marital', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
    "stages = [] # stages in our Pipeline\n",
    "for categoricalCol in CATE_FEATURES:\n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\")\n",
    "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()],\n",
    "                                     outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f17de1",
   "metadata": {},
   "source": [
    "Index the label feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "545cafcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert label into label indices using the StringIndexer\n",
    "label_stringIdx =  StringIndexer(inputCol=\"label\", outputCol=\"newlabel\")\n",
    "stages += [label_stringIdx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9cd166",
   "metadata": {},
   "source": [
    "Add continuous variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e6fa5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "assemblerInputs = [c + \"classVec\" for c in CATE_FEATURES] + CONTI_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97676777",
   "metadata": {},
   "source": [
    "Assemble the steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2f16942",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "438dc78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pipeline.\n",
    "pipeline = Pipeline(stages=stages)\n",
    "pipelineModel = pipeline.fit(df_remove)\n",
    "model = pipelineModel.transform(df_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f9d4bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/13 21:53:08 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(age=39.0, age_square=1521.0, workclass=' State-gov', fnlwgt=77516.0, education=' Bachelors', education_num=13.0, marital=' Never-married', occupation=' Adm-clerical', relationship=' Not-in-family', race=' White', sex=' Male', capital_gain=2174.0, capital_loss=0.0, hours_week=40.0, native_country=' United-States', label=' <=50K', workclassIndex=4.0, workclassclassVec=SparseVector(8, {4: 1.0}), educationIndex=2.0, educationclassVec=SparseVector(15, {2: 1.0}), maritalIndex=1.0, maritalclassVec=SparseVector(6, {1: 1.0}), occupationIndex=3.0, occupationclassVec=SparseVector(14, {3: 1.0}), relationshipIndex=1.0, relationshipclassVec=SparseVector(5, {1: 1.0}), raceIndex=0.0, raceclassVec=SparseVector(4, {0: 1.0}), sexIndex=0.0, sexclassVec=SparseVector(1, {0: 1.0}), native_countryIndex=0.0, native_countryclassVec=SparseVector(41, {0: 1.0}), newlabel=0.0, features=SparseVector(100, {4: 1.0, 10: 1.0, 24: 1.0, 32: 1.0, 44: 1.0, 48: 1.0, 52: 1.0, 53: 1.0, 94: 39.0, 95: 77516.0, 96: 2174.0, 97: 13.0, 99: 40.0}))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f8d4f1",
   "metadata": {},
   "source": [
    "# Step 4: Build the classifier: logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61411f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features to DenseVector type\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "input_data = model.rdd.map(lambda x: (x[\"newlabel\"], DenseVector(x[\"features\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "699ec9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|[0.0,0.0,0.0,0.0,...|\n",
      "|  0.0|[0.0,1.0,0.0,0.0,...|\n",
      "+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_train = sqlContext.createDataFrame(input_data, [\"label\", \"features\"])\n",
    "df_train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e882370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "train_data, test_data = df_train.randomSplit([.8,.2],seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "748d98fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 69:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|       19845|\n",
      "|  1.0|        6300|\n",
      "+-----+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_data.groupby('label').agg({'label': 'count'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dc9f67",
   "metadata": {},
   "source": [
    "Build the logistic regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b8c8b7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Import `LinearRegression`\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Initialize `lr`\n",
    "lr = LogisticRegression(labelCol=\"label\",\n",
    "                        featuresCol=\"features\",\n",
    "                        maxIter=10,\n",
    "                        regParam=0.3)\n",
    "\n",
    "# Fit the data to the model\n",
    "linearModel = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "194fd436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.019704415599421946,-0.04982616153530313,0.009957780753977514,-0.15197364265389735,-0.0418392848632432,0.29501683299268133,0.25200713332290364,-0.44584274196105517,-0.1390464876454707,-0.04559227585344077,0.22725471765192207,0.3741533797695234,0.025192204503802842,-0.2197444034656236,-0.000734006757600373,-0.2345416446992782,-0.26261718005155316,0.5298482210560835,-0.24639552187076896,-0.14377816479027514,0.562405521023547,-0.2517202792220073,-0.23134070298936846,0.4046089219773184,-0.31074963371953973,-0.16503822113107325,-0.20454477020297604,-0.14452757691138546,-0.16480289136299972,0.2336674519593504,-0.03095606810320328,0.3458586726214789,-0.08813620100083785,0.063444441349853,-0.2506336626209868,-0.1663569726091154,-0.15257182016482726,-0.10199338163653328,-0.23756455468190846,-0.28891540517056863,0.16041622234030592,0.13108642860470776,-0.2523324736648386,0.33505903505460266,-0.18084411856632707,-0.28435606027328947,-0.21479597537699746,0.46179393622741954,0.08270708674220908,-0.07982370650933754,0.0031206526651827793,-0.15923842022982537,0.18994070097806745,0.07442875057842631,-0.2339572167555353,-0.009262073876600965,0.12389566397834198,0.10225631285300893,0.174917722275189,-0.12801771863939224,-0.15121663933377844,0.09525485064730273,-0.012235353707460069,0.10500885161069522,-0.05006033488262042,-0.15450372180060765,-0.1385946350321478,0.10872859776719414,-0.2529166781054299,-0.22318330710226106,-0.1548215637207896,0.12262087695510006,-0.15309018168427943,-0.32895789296794536,0.0774319814582146,-0.15698906545730199,0.10185090440856215,-0.22700557345828593,-0.3278367693695322,-0.2535211037783267,0.15423661676430606,-0.09289272298090055,-0.2122685547974266,0.09284297271246916,-0.09008757105603335,0.3552550801317421,-0.10474145461965473,-0.17568905213962363,-0.21612323986085602,0.32378288495221375,-0.3960676037153925,-0.10135223640720817,0.2706930280866182,-0.09930811874368606,0.008521376291039282,4.582869723210128e-08,1.9505513049333256e-05,0.06391479785271709,0.00022297148859879034,0.009690687174806423]\n",
      "Intercept: -3.1230150116605646\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(linearModel.coefficients))\n",
    "print(\"Intercept: \" + str(linearModel.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320e88f6",
   "metadata": {},
   "source": [
    "# Step 5: Train and Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8124df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data using the transform() method.\n",
    "predictions = linearModel.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "554aeb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "527892fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 98:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+\n",
      "|label|prediction|         probability|\n",
      "+-----+----------+--------------------+\n",
      "|  0.0|       0.0|[0.71069421383421...|\n",
      "|  0.0|       0.0|[0.76011103389319...|\n",
      "|  0.0|       0.0|[0.86827677419728...|\n",
      "|  0.0|       0.0|[0.84882326891334...|\n",
      "|  0.0|       0.0|[0.77203315387320...|\n",
      "|  0.0|       0.0|[0.75559589049716...|\n",
      "|  0.0|       0.0|[0.85095920684329...|\n",
      "|  0.0|       0.0|[0.77768784610477...|\n",
      "|  0.0|       0.0|[0.89504914187700...|\n",
      "|  0.0|       0.0|[0.83052250933635...|\n",
      "|  0.0|       0.0|[0.87367767860783...|\n",
      "|  0.0|       0.0|[0.88913671135658...|\n",
      "|  0.0|       0.0|[0.88031296563766...|\n",
      "|  0.0|       0.0|[0.90212554225162...|\n",
      "|  0.0|       0.0|[0.90475637277970...|\n",
      "|  0.0|       0.0|[0.67993939606354...|\n",
      "|  0.0|       1.0|[0.28248646935375...|\n",
      "|  0.0|       0.0|[0.66724320322528...|\n",
      "|  0.0|       0.0|[0.90588063275955...|\n",
      "|  0.0|       0.0|[0.84436603916465...|\n",
      "+-----+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "selected = predictions.select(\"label\", \"prediction\", \"probability\")\n",
    "selected.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a799593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame with the label and the prediction\n",
    "cm = predictions.select(\"label\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3f3b30bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 99:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|        4875|\n",
      "|  1.0|        1541|\n",
      "+-----+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# check the number of class in the label and prediction\n",
    "cm.groupby('label').agg({'label': 'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c8fe801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 102:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|prediction|count(prediction)|\n",
      "+----------+-----------------+\n",
      "|       0.0|             5740|\n",
      "|       1.0|              676|\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cm.groupby('prediction').agg({'prediction': 'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6bab4bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8271508728179551"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute accuracy\n",
    "cm.filter(cm.label == cm.prediction).count() / cm.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a47285e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 114:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 82.715%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def accuracy_m(model): \n",
    "    predictions = model.transform(test_data)\n",
    "    cm = predictions.select(\"label\", \"prediction\")\n",
    "    acc = cm.filter(cm.label == cm.prediction).count() / cm.count()\n",
    "    print(\"Model accuracy: %.3f%%\" % (acc * 100)) \n",
    "accuracy_m(model = linearModel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e900f6fb",
   "metadata": {},
   "source": [
    "### ROC Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f7eaa8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8855630210153249\n",
      "areaUnderROC\n"
     ]
    }
   ],
   "source": [
    "### Use ROC \n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "print(evaluator.evaluate(predictions))\n",
    "print(evaluator.getMetricName())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e10489b",
   "metadata": {},
   "source": [
    "### Step 6: Tune the Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3246a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.5])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6d7f422e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train model: 58.258 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import *\n",
    "start_time = time()\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr,\n",
    "                    estimatorParamMaps=paramGrid,\n",
    "                    evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(train_data)\n",
    "# likely take a fair amount of time\n",
    "end_time = time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Time to train model: %.3f seconds\" % elapsed_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fd00cef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 527:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 84.944%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "accuracy_m(model = cvModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "066acc9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_503401207307', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 2,\n",
       " Param(parent='LogisticRegression_503401207307', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0,\n",
       " Param(parent='LogisticRegression_503401207307', name='family', doc='The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial'): 'auto',\n",
       " Param(parent='LogisticRegression_503401207307', name='featuresCol', doc='features column name.'): 'features',\n",
       " Param(parent='LogisticRegression_503401207307', name='fitIntercept', doc='whether to fit an intercept term.'): True,\n",
       " Param(parent='LogisticRegression_503401207307', name='labelCol', doc='label column name.'): 'label',\n",
       " Param(parent='LogisticRegression_503401207307', name='maxBlockSizeInMB', doc='maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be >= 0.'): 0.0,\n",
       " Param(parent='LogisticRegression_503401207307', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       " Param(parent='LogisticRegression_503401207307', name='predictionCol', doc='prediction column name.'): 'prediction',\n",
       " Param(parent='LogisticRegression_503401207307', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'): 'probability',\n",
       " Param(parent='LogisticRegression_503401207307', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'): 'rawPrediction',\n",
       " Param(parent='LogisticRegression_503401207307', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n",
       " Param(parent='LogisticRegression_503401207307', name='standardization', doc='whether to standardize the training features before fitting the model.'): True,\n",
       " Param(parent='LogisticRegression_503401207307', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.5,\n",
       " Param(parent='LogisticRegression_503401207307', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0).'): 1e-06}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel = cvModel.bestModel\n",
    "bestModel.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac92e52c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
