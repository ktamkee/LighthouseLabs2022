{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Demo\n",
    "\n",
    "Notebook from [Eric Elmoznino](https://github.com/EricElmoznino/lighthouse_nlp_II).\n",
    "\n",
    "![workflow](images/sentiment_workflow.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset\n",
    "\n",
    "Dataset is downloaded from [here](https://www.kaggle.com/code/kerneler/starter-imdb-master-csv-19b6829a-2/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10000_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10001_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10002_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>test</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10003_3.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type                                             review label  \\\n",
       "0           0  test  Once again Mr. Costner has dragged out a movie...   neg   \n",
       "1           1  test  This is an example of why the majority of acti...   neg   \n",
       "2           2  test  First of all I hate those moronic rappers, who...   neg   \n",
       "3           3  test  Not even the Beatles could write songs everyon...   neg   \n",
       "4           4  test  Brass pictures (movies is not a fitting word f...   neg   \n",
       "\n",
       "          file  \n",
       "0      0_2.txt  \n",
       "1  10000_4.txt  \n",
       "2  10001_1.txt  \n",
       "3  10002_3.txt  \n",
       "4  10003_3.txt  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "imdb_df = pd.read_csv('data/imdb_master.csv', encoding = \"ISO-8859-1\")\n",
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unsup    50000\n",
       "neg      25000\n",
       "pos      25000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only consider positive and negative reviews\n",
    "imdb_df = imdb_df[imdb_df['label'].str.startswith(('pos','neg'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing to a numeric representation\n",
    "\n",
    "The current data is in the form of moview reviews (text paragraphs) and their targets (`pos` or `neg`). \n",
    "We need to encode movie reviews into feature vectors so that we can train supervised machine learning models with `scikit-learn`. \n",
    "How can we do this?\n",
    "\n",
    "#### Create binarized word frequency counts (`X_binary`)\n",
    "Turn the text into sparse vector of word frequency counts using [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) from  `scikit-learn`. \n",
    "\n",
    "When you reproduce this, explore the arguments of `CountVectorizer` (e.g., [`stop_words`](https://scikit-learn.org/stable/modules/feature_extraction.html#stop-words), `ngram_range`, `max_features`, `min_df`, `tokenizer`, and `binary`).  \n",
    "\n",
    "The intuition behind using binarized representation is that for sentiment analysis word occurrence may matter more than word frequency. For instance, the occurrence of the word _excellent_ tells us a lot and the fact that it occurs four times may not tell us much more. This is just a hypothesis that you could test, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tokenization\n",
    "import nltk\n",
    "# For converting words into frequency counts\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step in pipeline\n",
    "# Keep words that appear in atleast 2 documents, keeps 5000 most common words\n",
    "preprocessor = CountVectorizer(min_df=2, tokenizer=nltk.word_tokenize, max_features=5000, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing output shape: (1000, 5000)\n",
      "First datapoint: Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrifi\n",
      "First datapoint tokens: ['Once', 'again', 'Mr.', 'Costner', 'has', 'dragged', 'out', 'a', 'movie', 'for']\n",
      "First datapoint Binary Bag of Words (sparse) representation:\n",
      "  (0, 13)\t1\n",
      "  (0, 20)\t1\n",
      "  :\t:\n",
      "  (0, 4866)\t1\n",
      "  (0, 4889)\t1\n",
      "  (0, 4898)\t1\n",
      "First datapoint Binary Bag of Words (dense) representation:\n",
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Demo the preprocessor:\n",
    "X_example = preprocessor.fit_transform(imdb_df['review'].iloc[:1000])\n",
    "print(f'Preprocessing output shape: {X_example.shape}')\n",
    "\n",
    "# Show the process for the first datapoint\n",
    "first_datapoint = imdb_df['review'].iloc[0]\n",
    "print(f'First datapoint: {first_datapoint[:100]}')\n",
    "\n",
    "first_tokens = nltk.word_tokenize(first_datapoint)\n",
    "print(f'First datapoint tokens: {first_tokens[:10]}')\n",
    "\n",
    "first_bow = preprocessor.transform([first_datapoint])\n",
    "first_bow.maxprint = 5  # Change how many of the non-zero elements are printing to not clutter the notebook\n",
    "print(f'First datapoint Binary Bag of Words (sparse) representation:\\n{first_bow}')\n",
    "print(f'First datapoint Binary Bag of Words (dense) representation:\\n{first_bow.todense()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "What is the disadvantage of using something like a *Bag of Words* representation for the documents in sentiment analysis?\n",
    "\n",
    "### Answer\n",
    "You lose the word order, and therefore the syntax. For instance, negation is lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB # Bernoulli because we have binary features\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([('preprocessing', preprocessor), \n",
    "                     ('model', BernoulliNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(imdb_df['review'], imdb_df['label'], test_size=0.20, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:\t0.85295\n",
      "Test accuracy:\t0.8397\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "train_accuracy = pipeline.score(X_train, y_train)\n",
    "test_accuracy = pipeline.score(X_test, y_test)\n",
    "\n",
    "print(f'Train accuracy:\\t{train_accuracy}')\n",
    "print(f'Test accuracy:\\t{test_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
