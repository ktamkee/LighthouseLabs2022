{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained Word2Vec Model From Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Users/karina/LighthouseLabs/GoogleNews-vectors-negative300.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/karina/GitHub/LighthouseLabs2022/Week_8/Notes/NLP/Word2Vec_Google.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/karina/GitHub/LighthouseLabs2022/Week_8/Notes/NLP/Word2Vec_Google.ipynb#ch0000001?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m KeyedVectors\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/karina/GitHub/LighthouseLabs2022/Week_8/Notes/NLP/Word2Vec_Google.ipynb#ch0000001?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m KeyedVectors\u001b[39m.\u001b[39;49mload_word2vec_format(\u001b[39m'\u001b[39;49m\u001b[39mUsers/karina/LighthouseLabs/GoogleNews-vectors-negative300.bin\u001b[39;49m\u001b[39m'\u001b[39;49m, binary\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py:1723\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py?line=1675'>1676</a>\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py?line=1676'>1677</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_word2vec_format\u001b[39m(\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py?line=1677'>1678</a>\u001b[0m         \u001b[39mcls\u001b[39m, fname, fvocab\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, binary\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m'\u001b[39m, unicode_errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py?line=1678'>1679</a>\u001b[0m         limit\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, datatype\u001b[39m=\u001b[39mREAL, no_header\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py?line=1679'>1680</a>\u001b[0m     ):\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py?line=1680'>1681</a>\u001b[0m     \u001b[39m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py?line=1681'>1682</a>\u001b[0m \n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py?line=1682'>1683</a>\u001b[0m \u001b[39m    Warnings\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py?line=1720'>1721</a>\u001b[0m \n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py?line=1721'>1722</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py?line=1722'>1723</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_word2vec_format(\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py?line=1723'>1724</a>\u001b[0m         \u001b[39mcls\u001b[39;49m, fname, fvocab\u001b[39m=\u001b[39;49mfvocab, binary\u001b[39m=\u001b[39;49mbinary, encoding\u001b[39m=\u001b[39;49mencoding, unicode_errors\u001b[39m=\u001b[39;49municode_errors,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py?line=1724'>1725</a>\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit, datatype\u001b[39m=\u001b[39;49mdatatype, no_header\u001b[39m=\u001b[39;49mno_header,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py?line=1725'>1726</a>\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py:2052\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py?line=2048'>2049</a>\u001b[0m             counts[word] \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(count)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py?line=2050'>2051</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mloading projection weights from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, fname)\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py?line=2051'>2052</a>\u001b[0m \u001b[39mwith\u001b[39;00m utils\u001b[39m.\u001b[39;49mopen(fname, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m fin:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py?line=2052'>2053</a>\u001b[0m     \u001b[39mif\u001b[39;00m no_header:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py?line=2053'>2054</a>\u001b[0m         \u001b[39m# deduce both vocab_size & vector_size from 1st pass over file\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py?line=2054'>2055</a>\u001b[0m         \u001b[39mif\u001b[39;00m binary:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/smart_open/smart_open_lib.py:188\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/smart_open/smart_open_lib.py?line=184'>185</a>\u001b[0m \u001b[39mif\u001b[39;00m transport_params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/smart_open/smart_open_lib.py?line=185'>186</a>\u001b[0m     transport_params \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/smart_open/smart_open_lib.py?line=187'>188</a>\u001b[0m fobj \u001b[39m=\u001b[39m _shortcut_open(\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/smart_open/smart_open_lib.py?line=188'>189</a>\u001b[0m     uri,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/smart_open/smart_open_lib.py?line=189'>190</a>\u001b[0m     mode,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/smart_open/smart_open_lib.py?line=190'>191</a>\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/smart_open/smart_open_lib.py?line=191'>192</a>\u001b[0m     buffering\u001b[39m=\u001b[39;49mbuffering,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/smart_open/smart_open_lib.py?line=192'>193</a>\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/smart_open/smart_open_lib.py?line=193'>194</a>\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/smart_open/smart_open_lib.py?line=194'>195</a>\u001b[0m     newline\u001b[39m=\u001b[39;49mnewline,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/smart_open/smart_open_lib.py?line=195'>196</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/smart_open/smart_open_lib.py?line=196'>197</a>\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/smart_open/smart_open_lib.py?line=197'>198</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m fobj\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/smart_open/smart_open_lib.py:361\u001b[0m, in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/smart_open/smart_open_lib.py?line=357'>358</a>\u001b[0m \u001b[39mif\u001b[39;00m errors \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/smart_open/smart_open_lib.py?line=358'>359</a>\u001b[0m     open_kwargs[\u001b[39m'\u001b[39m\u001b[39merrors\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m errors\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.8/site-packages/smart_open/smart_open_lib.py?line=360'>361</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _builtin_open(local_path, mode, buffering\u001b[39m=\u001b[39;49mbuffering, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mopen_kwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Users/karina/LighthouseLabs/GoogleNews-vectors-negative300.bin'"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('Users/karina/LighthouseLabs/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = model['easy']\n",
    "# see the shape of the vector (300,)\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good', 0.6836091876029968),\n",
       " ('lovely', 0.6676310896873474),\n",
       " ('neat', 0.6616737246513367),\n",
       " ('fantastic', 0.6569241881370544),\n",
       " ('wonderful', 0.6561347246170044),\n",
       " ('terrific', 0.6552367806434631),\n",
       " ('great', 0.6454657912254333),\n",
       " ('awesome', 0.6404187083244324),\n",
       " ('nicer', 0.6302445530891418),\n",
       " ('decent', 0.5993332266807556)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the most similar words to any word\n",
    "model.most_similar(\"nice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68360907"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the similarity score of any two words\n",
    "model.similarity(\"nice\",\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7190052"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Antonyms will have highly similar scores\n",
    "# Opposite words can be replaced with each other in text\n",
    "model.similarity(\"bad\",\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192911148071),\n",
       " ('monarch', 0.6189674735069275),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321243286133),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.5181134343147278),\n",
       " ('sultan', 0.5098593235015869),\n",
       " ('monarchy', 0.5087411403656006)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relationship between words\n",
    "# king - queen = man - woman\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boy', 0.808031439781189),\n",
       " ('teenager', 0.6755870580673218),\n",
       " ('teenage_girl', 0.6386616826057434),\n",
       " ('man', 0.6255338191986084),\n",
       " ('lad', 0.616614043712616),\n",
       " ('schoolgirl', 0.6113480925559998),\n",
       " ('schoolboy', 0.6011566519737244),\n",
       " ('son', 0.5938458442687988),\n",
       " ('father', 0.5887871384620667),\n",
       " ('uncle', 0.5734449028968811)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mom - girl = dad - boy\n",
    "model.most_similar(positive=['girl', 'dad'], negative=['mom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('madrid', 0.5295541286468506),\n",
       " ('dubai', 0.509259819984436),\n",
       " ('heidi', 0.48901548981666565),\n",
       " ('portugal', 0.48763689398765564),\n",
       " ('paula', 0.48557141423225403),\n",
       " ('alex', 0.480734646320343),\n",
       " ('lohan', 0.4801103472709656),\n",
       " ('diego', 0.48010095953941345),\n",
       " ('florence', 0.47695302963256836),\n",
       " ('costa', 0.4761490225791931)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# france - paris, spain - madrid\n",
    "model.most_similar(positive=['paris', 'spain'], negative=['france'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('daughter', 0.6066097021102905),\n",
       " ('niece', 0.5490824580192566),\n",
       " ('granddaughter', 0.540050745010376),\n",
       " ('aunt', 0.5397382974624634),\n",
       " ('husband', 0.5387389659881592),\n",
       " ('sister', 0.5360148549079895),\n",
       " ('son', 0.5356959104537964),\n",
       " ('wife', 0.5313628911972046),\n",
       " ('father', 0.5261732339859009),\n",
       " ('grandmother', 0.5253341197967529)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mother - daughter, table - chair\n",
    "model.most_similar(positive=['chair', 'mother'], negative=['table'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implemeting Word2Vec with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "scrapped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Artificial_intelligence')\n",
    "article = scrapped_data .read()\n",
    "\n",
    "parsed_article = bs.BeautifulSoup(article,'lxml')\n",
    "\n",
    "paragraphs = parsed_article.find_all('p')\n",
    "\n",
    "article_text = \"\"\n",
    "\n",
    "for p in paragraphs:\n",
    "    article_text += p.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaing the text\n",
    "processed_article = article_text.lower()\n",
    "processed_article = re.sub('[^a-zA-Z]', ' ', processed_article ) # convert to lowercase\n",
    "processed_article = re.sub(r'\\s+', ' ', processed_article) # remove all digits, special characters and extra spaces\n",
    "\n",
    "# Preparing the dataset\n",
    "all_sentences = nltk.sent_tokenize(processed_article) # convert to sentences\n",
    "\n",
    "all_words = [nltk.word_tokenize(sent) for sent in all_sentences] # convert to words\n",
    "\n",
    "# Removing Stop Words\n",
    "from nltk.corpus import stopwords\n",
    "for i in range(len(all_words)):\n",
    "    all_words[i] = [w for w in all_words[i] if w not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec = Word2Vec(all_words, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ai': 0, 'intelligence': 1, 'artificial': 2, 'learning': 3, 'human': 4, 'used': 5, 'research': 6, 'machine': 7, 'use': 8, 'many': 9, 'problems': 10, 'networks': 11, 'also': 12, 'data': 13, 'knowledge': 14, 'search': 15, 'intelligent': 16, 'researchers': 17, 'agent': 18, 'world': 19, 'neural': 20, 'algorithms': 21, 'general': 22, 'field': 23, 'symbolic': 24, 'logic': 25, 'may': 26, 'information': 27, 'machines': 28, 'states': 29, 'systems': 30, 'would': 31, 'system': 32, 'mind': 33, 'problem': 34, 'computer': 35, 'one': 36, 'goal': 37, 'example': 38, 'cyber': 39, 'applications': 40, 'reasoning': 41, 'could': 42, 'however': 43, 'goals': 44, 'risk': 45, 'humans': 46, 'technology': 47, 'diplomacy': 48, 'cybersecurity': 49, 'security': 50, 'approaches': 51, 'program': 52, 'specific': 53, 'russia': 54, 'scientific': 55, 'using': 56, 'computing': 57, 'since': 58, 'developed': 59, 'optimization': 60, 'including': 61, 'language': 62, 'mathematical': 63, 'solve': 64, 'recognition': 65, 'known': 66, 'algorithm': 67, 'decision': 68, 'become': 69, 'number': 70, 'deep': 71, 'well': 72, 'tools': 73, 'united': 74, 'include': 75, 'two': 76, 'ability': 77, 'theory': 78, 'term': 79, 'called': 80, 'difficult': 81, 'behavior': 82, 'software': 83, 'even': 84, 'based': 85, 'national': 86, 'uses': 87, 'u': 88, 'creating': 89, 'neurons': 90, 'first': 91, 'form': 92, 'new': 93, 'future': 94, 'level': 95, 'know': 96, 'us': 97, 'widely': 98, 'programs': 99, 'make': 100, 'input': 101, 'people': 102, 'examples': 103, 'particular': 104, 'objects': 105, 'natural': 106, 'sub': 107, 'whether': 108, 'google': 109, 'model': 110, 'planning': 111, 'science': 112, 'nations': 113, 'robotics': 114, 'others': 115, 'process': 116, 'several': 117, 'large': 118, 'fiction': 119, 'processing': 120, 'learn': 121, 'time': 122, 'increase': 123, 'perception': 124, 'issue': 125, 'described': 126, 'development': 127, 'political': 128, 'techniques': 129, 'question': 130, 'inputs': 131, 'real': 132, 'via': 133, 'analysis': 134, 'approach': 135, 'robots': 136, 'turing': 137, 'person': 138, 'methods': 139, 'market': 140, 'rather': 141, 'beings': 142, 'related': 143, 'tasks': 144, 'brain': 145, 'formal': 146, 'actions': 147, 'successful': 148, 'often': 149, 'solving': 150, 'president': 151, 'foreign': 152, 'together': 153, 'choices': 154, 'processes': 155, 'weapons': 156, 'military': 157, 'simple': 158, 'tool': 159, 'patents': 160, 'requires': 161, 'like': 162, 'solutions': 163, 'patent': 164, 'makes': 165, 'inspired': 166, 'ukraine': 167, 'making': 168, 'facts': 169, 'relations': 170, 'drones': 171, 'commonsense': 172, 'logics': 173, 'companies': 174, 'china': 175, 'cyberspace': 176, 'life': 177, 'thus': 178, 'became': 179, 'easy': 180, 'things': 181, 'representation': 182, 'application': 183, 'long': 184, 'early': 185, 'means': 186, 'communication': 187, 'network': 188, 'classifiers': 189, 'considered': 190, 'various': 191, 'due': 192, 'environment': 193, 'economics': 194, 'industry': 195, 'philosophy': 196, 'argues': 197, 'statistical': 198, 'internet': 199, 'autonomous': 200, 'facebook': 201, 'according': 202, 'three': 203, 'far': 204, 'largest': 205, 'soft': 206, 'allow': 207, 'understanding': 208, 'capable': 209, 'german': 210, 'billion': 211, 'works': 212, 'effect': 213, 'projects': 214, 'generation': 215, 'go': 216, 'way': 217, 'prevent': 218, 'much': 219, 'order': 220, 'forms': 221, 'classification': 222, 'popular': 223, 'function': 224, 'outputs': 225, 'agents': 226, 'translation': 227, 'target': 228, 'modern': 229, 'facial': 230, 'analyze': 231, 'individual': 232, 'argue': 233, 'similar': 234, 'help': 235, 'experience': 236, 'calculus': 237, 'g': 238, 'bots': 239, 'identify': 240, 'layers': 241, 'institutions': 242, 'step': 243, 'election': 244, 'need': 245, 'improve': 246, 'advanced': 247, 'events': 248, 'terms': 249, 'definition': 250, 'change': 251, 'multi': 252, 'years': 253, 'students': 254, 'ethics': 255, 'part': 256, 'ethical': 257, 'r': 258, 'space': 259, 'russell': 260, 'highly': 261, 'around': 262, 'bias': 263, 'began': 264, 'still': 265, 'fields': 266, 'leader': 267, 'jobs': 268, 'principles': 269, 'technique': 270, 'simulate': 271, 'potential': 272, 'vision': 273, 'misinformation': 274, 'member': 275, 'laws': 276, 'surveillance': 277, 'computers': 278, 'among': 279, 'digital': 280, 'different': 281, 'rights': 282, 'century': 283, 'class': 284, 'domains': 285, 'central': 286, 'issues': 287, 'categories': 288, 'antiquity': 289, 'previous': 290, 'power': 291, 'company': 292, 'affairs': 293, 'e': 294, 'neuron': 295, 'training': 296, 'devices': 297, 'set': 298, 'common': 299, 'complex': 300, 'spread': 301, 'directly': 302, 'youtube': 303, 'layer': 304, 'putin': 305, 'image': 306, 'important': 307, 'right': 308, 'certain': 309, 'countries': 310, 'consequences': 311, 'c': 312, 'solution': 313, 'strategy': 314, 'computational': 315, 'sufficiently': 316, 'study': 317, 'stated': 318, 'eu': 319, 'possible': 320, 'classifier': 321, 'policy': 322, 'reach': 323, 'body': 324, 'lead': 325, 'move': 326, 'assist': 327, 'physical': 328, 'heuristics': 329, 'spam': 330, 'skills': 331, 'battlefield': 332, 'swarm': 333, 'warfare': 334, 'lethal': 335, 'patterns': 336, 'work': 337, 'designed': 338, 'main': 339, 'functions': 340, 'global': 341, 'truth': 342, 'made': 343, 'top': 344, 'classify': 345, 'size': 346, 'guess': 347, 'viewed': 348, 'campaign': 349, 'questions': 350, 'k': 351, 'require': 352, 'efforts': 353, 'although': 354, 'said': 355, 'leaders': 356, 'idea': 357, 'show': 358, 'sector': 359, 'narrow': 360, 'diplomatic': 361, 'feel': 362, 'followed': 363, 'simulated': 364, 'evolutionary': 365, 'japan': 366, 'ministry': 367, 'funding': 368, 'conflict': 369, 'care': 370, 'able': 371, 'reason': 372, 'included': 373, 'decisions': 374, 'introduced': 375, 'technologies': 376, 'percent': 377, 'partners': 378, 'european': 379, 'published': 380, 'test': 381, 'public': 382, 'paradigm': 383, 'speech': 384, 'achieve': 385, 'medical': 386, 'high': 387, 'diagnosis': 388, 'year': 389, 'success': 390, 'microsoft': 391, 'face': 392, 'logical': 393, 'self': 394, 'academic': 395, 'established': 396, 'something': 397, 'middle': 398, 'task': 399, 'demonstrated': 400, 'regression': 401, 'wide': 402, 'maximize': 403, 'precisely': 404, 'especially': 405, 'english': 406, 'connectionist': 407, 'pattern': 408, 'virtual': 409, 'interaction': 410, 'focused': 411, 'cognitive': 412, 'word': 413, 'longer': 414, 'heavily': 415, 'probability': 416, 'statistics': 417, 'failed': 418, 'ongoing': 419, 'integrated': 420, 'straightforward': 421, 'sources': 422, 'object': 423, 'within': 424, 'allows': 425, 'engineering': 426, 'founded': 427, 'robot': 428, 'routine': 429, 'classifies': 430, 'text': 431, 'recent': 432, 'commercial': 433, 'dynamic': 434, 'experts': 435, 'defined': 436, 'movement': 437, 'relationship': 438, 'governments': 439, 'assess': 440, 'winter': 441, 'chess': 442, 'automated': 443, 'ontologies': 444, 'humanity': 445, 'properties': 446, 'rarely': 447, 'ontology': 448, 'algorithmic': 449, 'create': 450, 'strategies': 451, 'fast': 452, 'driving': 453, 'recommendation': 454, 'concepts': 455, 'led': 456, 'accuracy': 457, 'attention': 458, 'benchmarks': 459, 'computation': 460, 'amazon': 461, 'concern': 462, 'design': 463, 'involves': 464, 'generally': 465, 'current': 466, 'total': 467, 'increased': 468, 'amount': 469, 'reported': 470, 'consider': 471, 'domain': 472, 'produce': 473, 'area': 474, 'support': 475, 'game': 476, 'fundamental': 477, 'given': 478, 'interest': 479, 'competition': 480, 'minsky': 481, 'rise': 482, 'marvin': 483, 'simon': 484, 'available': 485, 'state': 486, 'plan': 487, 'discovery': 488, 'express': 489, 'web': 490, 'fuzzy': 491, 'statements': 492, 'breadth': 493, 'true': 494, 'assume': 495, 'default': 496, 'st': 497, 'late': 498, 'philosophers': 499, 'animal': 500, 'finding': 501, 'typically': 502, 'knows': 503, 'focus': 504, 'searching': 505, 'gradient': 506, 'ibm': 507, 'becoming': 508, 'without': 509, 'role': 510, 'emerging': 511, 'measure': 512, 'services': 513, 'international': 514, 'filed': 515, 'organizations': 516, 'bayesian': 517, 'needed': 518, 'shift': 519, 'third': 520, 'federal': 521, 'identified': 522, 'programming': 523, 'innovation': 524, 'genetic': 525, 'open': 526, 'technological': 527, 'superintelligent': 528, 'better': 529, 'begin': 530, 'social': 531, 'might': 532, 'smart': 533, 'likely': 534, 'games': 535, 'matching': 536, 'conscious': 537, 'match': 538, 'harm': 539, 'higher': 540, 'morality': 541, 'relevant': 542, 'prominent': 543, 'race': 544, 'risks': 545, 'back': 546, 'becomes': 547, 'created': 548, 'operations': 549, 'addition': 550, 'defendants': 551, 'activation': 552, 'government': 553, 'creation': 554, 'tend': 555, 'extremely': 556, 'threat': 557, 'heart': 558, 'performance': 559, 'asimov': 560, 'trained': 561, 'playing': 562, 'champion': 563, 'automation': 564, 'benefit': 565, 'spreading': 566, 'handle': 567, 'chinese': 568, 'believe': 569, 'subjective': 570, 'teaching': 571, 'path': 572, 'simulation': 573, 'provides': 574, 'point': 575, 'n': 576, 'business': 577, 'critics': 578, 'agree': 579, 'considers': 580, 'proposed': 581, 'symbol': 582, 'moravec': 583, 'philosopher': 584, 'private': 585, 'superintelligence': 586, 'presented': 587, 'position': 588, 'firms': 589, 'friendly': 590, 'norvig': 591, 'founder': 592, 'deepfake': 593, 'ranging': 594, 'alan': 595, 'centuries': 596, 'claims': 597, 'institute': 598, 'compas': 599, 'unfair': 600, 'church': 601, 'raised': 602, 'possess': 603, 'internal': 604, 'healthcare': 605, 'thesis': 606, 'hypothetical': 607, 'along': 608, 'external': 609, 'philosophical': 610, 'arguments': 611, 'herbert': 612, 'researching': 613, 'assumption': 614, 'sense': 615, 'worth': 616, 'hawking': 617, 'connections': 618, 'provably': 619, 'ways': 620, 'sought': 621, 'reflect': 622, 'shut': 623, 'attempts': 624, 'resources': 625, 'suffer': 626, 'second': 627, 'accountability': 628, 'stephen': 629, 'consciousness': 630, 'deduction': 631, 'control': 632, 'upon': 633, 'korea': 634, 'act': 635, 'south': 636, 'psychology': 637, 'taking': 638, 'searle': 639, 'revolution': 640, 'explaining': 641, 'explain': 642, 'emerged': 643, 'name': 644, 'strong': 645, 'cybernetics': 646, 'mary': 647, 'shelley': 648, 'learned': 649, 'red': 650, 'frankenstein': 651, 'karel': 652, 'complete': 653, 'apek': 654, 'transhumanism': 655, 'clear': 656, 'recognized': 657, 'mankind': 658, 'computationalism': 659, 'beyond': 660, 'economists': 661, 'storytelling': 662, 'discussed': 663, 'appeared': 664, 'collar': 665, 'white': 666, 'neurobiology': 667, 'newell': 668, 'scientists': 669, 'unlike': 670, 'stuart': 671, 'suggested': 672, 'existential': 673, 'singularity': 674, 'proponents': 675, 'peter': 676, 'named': 677, 'hard': 678, 'gofai': 679, 'plans': 680, 'increasing': 681, 'rational': 682, 'beneficial': 683, 'explored': 684, 'sentiment': 685, 'range': 686, 'nation': 687, 'videos': 688, 'wing': 689, 'engines': 690, 'words': 691, 'sway': 692, 'seen': 693, 'limit': 694, 'competence': 695, 'acting': 696, 'every': 697, 'biometric': 698, 'major': 699, 'rejected': 700, 'authentication': 701, 'twitter': 702, 'trump': 703, 'clinton': 704, 'miss': 705, 'netflix': 706, 'overwhelming': 707, 'analyzing': 708, 'siri': 709, 'alexa': 710, 'engaging': 711, 'cset': 712, 'cars': 713, 'war': 714, 'gathers': 715, 'involving': 716, 'competing': 717, 'highest': 718, 'identity': 719, 'live': 720, 'riiid': 721, 'perceives': 722, 'caused': 723, 'errors': 724, 'refugee': 725, 'un': 726, 'covid': 727, 'displayed': 728, 'health': 729, 'gather': 730, 'society': 731, 'relay': 732, 'meta': 733, 'mitigate': 734, 'trustworthy': 735, 'deploying': 736, 'product': 737, 'vital': 738, 'takes': 739, 'medicine': 740, 'doctors': 741, 'achieving': 742, 'scans': 743, 'diagnose': 744, 'previously': 745, 'employ': 746, 'describe': 747, 'display': 748, 'enables': 749, 'handling': 750, 'economic': 751, 'associated': 752, 'brings': 753, 'bring': 754, 'share': 755, 'day': 756, 'trust': 757, 'calling': 758, 'commission': 759, 'helping': 760, 'rare': 761, 'proved': 762, 'dominated': 763, 'increasingly': 764, 'culture': 765, 'series': 766, 'almost': 767, 'novel': 768, 'dick': 769, 'decades': 770, 'centered': 771, 'values': 772, 'usa': 773, 'russian': 774, 'manyika': 775, 'canada': 776, 'released': 777, 'adopted': 778, 'regulation': 779, 'investment': 780, 'developing': 781, 'responsible': 782, 'manipulate': 783, 'tech': 784, 'serious': 785, 'musk': 786, 'bill': 787, 'following': 788, 'nuclear': 789, 'intentions': 790, 'experienced': 791, 'service': 792, 'office': 793, 'governmental': 794, 'hub': 795, 'phenomenon': 796, 'establish': 797, 'behalf': 798, 'effort': 799, 'frequently': 800, 'mission': 801, 'september': 802, 'overall': 803, 'diplomats': 804, 'detected': 805, 'agenda': 806, 'taken': 807, 'waves': 808, 'authority': 809, 'czech': 810, 'unique': 811, 'defence': 812, 'line': 813, 'malicious': 814, 'secure': 815, 'simulating': 816, 'deployed': 817, 'take': 818, 'ukrainian': 819, 'come': 820, 'databases': 821, 'james': 822, 'argued': 823, 'neats': 824, 'simplest': 825, 'value': 826, 'valuable': 827, 'allowing': 828, 'key': 829, 'uncertainty': 830, 'models': 831, 'markov': 832, 'prediction': 833, 'cooperation': 834, 'filtering': 835, 'operate': 836, 'ml': 837, 'concept': 838, 'belief': 839, 'situation': 840, 'finds': 841, 'non': 842, 'supervised': 843, 'degree': 844, 'ant': 845, 'determine': 846, 'belongs': 847, 'guesses': 848, 'landscape': 849, 'random': 850, 'blind': 851, 'came': 852, 'smaller': 853, 'learners': 854, 'utility': 855, 'divided': 856, 'interpret': 857, 'predictions': 858, 'attempt': 859, 'weighted': 860, 'perform': 861, 'average': 862, 'distribution': 863, 'depends': 864, 'represented': 865, 'description': 866, 'represent': 867, 'scalability': 868, 'bayes': 869, 'naive': 870, 'displaced': 871, 'svm': 872, 'neighbor': 873, 'nearest': 874, 'classified': 875, 'told': 876, 'changing': 877, 'observation': 878, 'enormous': 879, 'combined': 880, 'observations': 881, 'retrieval': 882, 'areas': 883, 'therefore': 884, 'pick': 885, 'controllers': 886, 'diamond': 887, 'best': 888, 'supply': 889, 'tree': 890, 'serve': 891, 'generate': 892, 'sensors': 893, 'signals': 894, 'active': 895, 'attempting': 896, 'inference': 897, 'visual': 898, 'proof': 899, 'location': 900, 'visible': 901, 'interior': 902, 'features': 903, 'motion': 904, 'hopes': 905, 'architecture': 906, 'joint': 907, 'movements': 908, 'maintaining': 909, 'despite': 910, 'affective': 911, 'hans': 912, 'assistants': 913, 'programmed': 914, 'develop': 915, 'otherwise': 916, 'give': 917, 'existing': 918, 'actually': 919, 'successes': 920, 'translators': 921, 'another': 922, 'near': 923, 'understand': 924, 'maps': 925, 'steps': 926, 'good': 927, 'responses': 928, 'ones': 929, 'never': 930, 'applied': 931, 'result': 932, 'complexity': 933, 'sample': 934, 'required': 935, 'nlp': 936, 'grows': 937, 'quickly': 938, 'appears': 939, 'powerful': 940, 'written': 941, 'sufficient': 942, 'texts': 943, 'searches': 944, 'local': 945, 'answering': 946, 'moving': 947, 'translate': 948, 'structure': 949, 'useful': 950, 'find': 951, 'occurrence': 952, 'fire': 953, 'wire': 954, 'impossible': 955, 'response': 956, 'british': 957, 'next': 958, 'later': 959, 'thinking': 960, 'noted': 961, 'revived': 962, 'matter': 963, 'thing': 964, 'machinery': 965, 'wrote': 966, 'jurisdictions': 967, 'responsibility': 968, 'legal': 969, 'fifth': 970, 'project': 971, 'beginning': 972, 'lisp': 973, 'agriculture': 974, 'entertainment': 975, 'sectors': 976, 'personal': 977, 'refer': 978, 'rodney': 979, 'brooks': 980, 'inventions': 981, 'four': 982, 'papers': 983, 'survive': 984, 'j': 985, 'john': 986, 'remaining': 987, 'continuous': 988, 'difficulty': 989, 'period': 990, 'away': 991, 'mistakes': 992, 'intellectual': 993, 'pushed': 994, 'gained': 995, 'prominence': 996, 'necessary': 997, 'produced': 998, 'see': 999, 'algebra': 1000, 'history': 1001, 'theorems': 1002, 'guided': 1003, 'funded': 1004, 'department': 1005, 'defense': 1006, 'directed': 1007, 'variety': 1008, 'eventually': 1009, 'analysts': 1010, 'predicted': 1011, 'pigeons': 1012, 'twenty': 1013, 'exactly': 1014, 'substantially': 1015, 'solved': 1016, 'define': 1017, 'recognize': 1018, 'david': 1019, 'hours': 1020, 'diverse': 1021, 'generalized': 1022, 'concerned': 1023, 'fully': 1024, 'reduce': 1025, 'convolutional': 1026, 'improved': 1027, 'agi': 1028, 'multiple': 1029, 'basis': 1030, 'traits': 1031, 'capabilities': 1032, 'expect': 1033, 'received': 1034, 'perceptrons': 1035, 'short': 1036, 'recurrent': 1037, 'puzzles': 1038, 'signal': 1039, 'deductions': 1040, 'dealing': 1041, 'uncertain': 1042, 'incomplete': 1043, 'feedforward': 1044, 'explosion': 1045, 'exponentially': 1046, 'competitive': 1047, 'descent': 1048, 'intelligently': 1049, 'exists': 1050, 'spectrum': 1051, 'numerous': 1052, 'cases': 1053, 'incorporated': 1054, 'thousands': 1055, 'deepmind': 1056, 'superhuman': 1057, 'jeopardy': 1058, 'verifiable': 1059, 'results': 1060, 'mathematics': 1061, 'beat': 1062, 'blue': 1063, 'access': 1064, 'deepfakes': 1065, 'enabled': 1066, 'advances': 1067, 'hungry': 1068, 'started': 1069, 'specialized': 1070, 'id': 1071, 'apple': 1072, 'targeted': 1073, 'daily': 1074, 'mainstream': 1075, 'usage': 1076, 'list': 1077, 'includes': 1078, 'hardware': 1079, 'infrastructure': 1080, 'survey': 1081, 'five': 1082, 'languages': 1083, 'textbooks': 1084}\n"
     ]
    }
   ],
   "source": [
    "vocabulary = word2vec.wv.key_to_index\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View vector representation of word\n",
    "v1 = word2vec.wv['artificial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ai', 0.5954935550689697),\n",
       " ('information', 0.5101127028465271),\n",
       " ('used', 0.5012791752815247),\n",
       " ('networks', 0.4910092353820801),\n",
       " ('agent', 0.4829583168029785),\n",
       " ('researchers', 0.4747096598148346),\n",
       " ('artificial', 0.4654604494571686),\n",
       " ('use', 0.4515644609928131),\n",
       " ('may', 0.4363589286804199),\n",
       " ('data', 0.43425726890563965)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing Similar Words\n",
    "sim_words = word2vec.wv.most_similar('intelligence')\n",
    "sim_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "39512f3c2a1741d7f752d45a133d4514127029333ea14bc2f3c6c5e6759b9029"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
